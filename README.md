# ğŸš€ Waste AI Backend

**Backend Intelligence Artificielle pour la Gestion des DÃ©chets au Burkina Faso**

[![Python](https://img.shields.io/badge/Python-3.11-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104-green.svg)](https://fastapi.tiangolo.com/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.15-orange.svg)](https://www.tensorflow.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

## ğŸ“‹ Table des MatiÃ¨res

1. [FonctionnalitÃ©s](#-fonctionnalitÃ©s)
2. [Architecture](#-architecture)
3. [Technologies](#-technologies)
4. [Installation](#-installation)
5. [Configuration](#-configuration)
6. [Utilisation](#-utilisation)
7. [API Endpoints](#-api-endpoints)
8. [ModÃ¨les IA](#-modÃ¨les-ia)
9. [Tests](#-tests)
10. [DÃ©ploiement](#-dÃ©ploiement)
11. [Contribution](#-contribution)

---

## ğŸ¯ FonctionnalitÃ©s

### 1. ğŸ—ºï¸ **Analyse de Risque**
- DÃ©tection automatique des zones Ã  risque
- Clustering ML (DBSCAN) sur donnÃ©es gÃ©ospatiales
- PrÃ©diction de niveaux de risque (Low/Medium/High/Critical)
- GÃ©nÃ©ration de heatmaps
- Identification des zones prioritaires

### 2. ğŸ–¼ï¸ **Classification d'Images**
- Classification automatique des types de dÃ©chets
- 9 classes : plastique, papier, aluminium, mÃ©dical, organique, verre, Ã©lectronique, textile, autre
- CNN basÃ© sur MobileNetV2 (transfer learning)
- Validation qualitÃ© d'image
- Confiance par classe

### 3. ğŸ“ **Estimation de Taille**
- Estimation de volume (mÂ³)
- Calcul de superficie (mÂ²)
- Estimation de hauteur (m)
- Calibration avec objets de rÃ©fÃ©rence
- Confidence score

---

## ğŸ—ï¸ Architecture
```
waste-ai-backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # FastAPI application
â”‚   â”œâ”€â”€ config.py            # Configuration
â”‚   â”œâ”€â”€ database.py          # Connexion BD Laravel
â”‚   â”‚
â”‚   â”œâ”€â”€ api/v1/              # Endpoints API
â”‚   â”‚   â”œâ”€â”€ risk_analysis.py
â”‚   â”‚   â”œâ”€â”€ classification.py
â”‚   â”‚   â””â”€â”€ size_estimation.py
â”‚   â”‚
â”‚   â”œâ”€â”€ models/              # ModÃ¨les IA
â”‚   â”‚   â”œâ”€â”€ risk_predictor.py
â”‚   â”‚   â”œâ”€â”€ waste_classifier.py
â”‚   â”‚   â””â”€â”€ size_estimator.py
â”‚   â”‚
â”‚   â”œâ”€â”€ services/            # Business logic
â”‚   â”‚   â”œâ”€â”€ image_processor.py
â”‚   â”‚   â”œâ”€â”€ data_fetcher.py
â”‚   â”‚   â””â”€â”€ result_saver.py
â”‚   â”‚
â”‚   â”œâ”€â”€ schemas/             # Pydantic models
â”‚   â”‚   â”œâ”€â”€ requests.py
â”‚   â”‚   â””â”€â”€ responses.py
â”‚   â”‚
â”‚   â””â”€â”€ utils/               # Utilitaires
â”‚       â”œâ”€â”€ image_utils.py
â”‚       â”œâ”€â”€ geo_utils.py
â”‚       â””â”€â”€ validators.py
â”‚
â”œâ”€â”€ trained_models/          # ModÃ¨les entraÃ®nÃ©s
â”œâ”€â”€ datasets/                # Datasets
â”œâ”€â”€ scripts/                 # Scripts d'entraÃ®nement
â”œâ”€â”€ tests/                   # Tests unitaires
â””â”€â”€ docker/                  # Docker configs
```

---

## ğŸ› ï¸ Technologies

### Backend & API
- **FastAPI** 0.104 - Framework API moderne
- **Uvicorn** - Serveur ASGI
- **Pydantic** - Validation de donnÃ©es
- **SQLAlchemy** - ORM pour PostgreSQL

### Machine Learning
- **TensorFlow** 2.15 - Deep Learning
- **scikit-learn** - ML classique
- **OpenCV** - Traitement d'images
- **Pillow** - Manipulation d'images

### RAG & LLM (Bonus)
- **ChromaDB** - Base vectorielle
- **sentence-transformers** - Embeddings
- **Ollama** - LLM local

### Base de DonnÃ©es
- **PostgreSQL** 15 - BD Laravel
- **ChromaDB** - Stockage vectoriel

### DevOps
- **Docker** & **Docker Compose**
- **pytest** - Tests
- **GitHub Actions** - CI/CD (Ã  venir)

---

## ğŸ“¦ Installation

### PrÃ©requis

- Python 3.11+
- PostgreSQL 15+
- Git
- (Optionnel) Docker & Docker Compose

### 1. Cloner le repository
```bash
git clone https://github.com/votre-org/waste-ai-backend.git
cd waste-ai-backend
```

### 2. CrÃ©er environnement virtuel
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

### 3. Installer les dÃ©pendances
```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### 4. Configurer les variables d'environnement
```bash
# Copier le fichier exemple
cp .env.example .env

# Ã‰diter .env avec vos configurations
notepad .env  # Windows
nano .env     # Linux/Mac
```

### 5. Initialiser la base de donnÃ©es
```bash
# Assurez-vous que PostgreSQL est lancÃ©
# La BD Laravel doit dÃ©jÃ  exister

# Tester la connexion
python -c "from app.database import engine; engine.connect(); print('âœ… BD connectÃ©e')"
```

### 6. (Optionnel) TÃ©lÃ©charger les modÃ¨les prÃ©-entraÃ®nÃ©s
```bash
# CrÃ©er dossier modÃ¨les
mkdir -p trained_models

# TÃ©lÃ©charger depuis Google Drive / S3
# TODO: Ajouter liens de tÃ©lÃ©chargement
```

---

## âš™ï¸ Configuration

### Fichier `.env`
```env
# API
API_HOST=0.0.0.0
API_PORT=8000
API_DEBUG=true

# Base de DonnÃ©es Laravel
DB_HOST=localhost
DB_PORT=5432
DB_NAME=waste_management
DB_USER=postgres
DB_PASSWORD=your_password

# ModÃ¨les IA
CLASSIFICATION_MODEL_PATH=./trained_models/waste_classifier_v1.h5
RISK_MODEL_PATH=./trained_models/risk_predictor.pkl

# RAG (Optionnel)
EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
VECTOR_DB_PATH=./data/chroma_db
LLM_PROVIDER=ollama
OLLAMA_MODEL=llama3.2

# CORS
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:8080
```

---

## ğŸš€ Utilisation

### DÃ©marrer le serveur
```bash
# Mode dÃ©veloppement (auto-reload)
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# Mode production
uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 4
```

### AccÃ©der Ã  la documentation

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
- **Health Check**: http://localhost:8000/health

---

## ğŸ“¡ API Endpoints

### ğŸ—ºï¸ Analyse de Risque

#### `GET /api/v1/risk/analyze`

Analyser les zones Ã  risque.

**ParamÃ¨tres:**
- `city` (optionnel): Ville Ã  analyser
- `days`: Nombre de jours (1-365, dÃ©faut: 30)
- `min_reports`: Min signalements par zone (dÃ©faut: 3)

**RÃ©ponse:**
```json
{
  "zones": [
    {
      "id": "zone_001",
      "latitude": 12.3714,
      "longitude": -1.5197,
      "risk_level": "high",
      "risk_score": 78.5,
      "report_count": 15,
      "recommendations": ["Intervention urgente"]
    }
  ],
  "heatmap_data": [...],
  "statistics": {...},
  "processing_time": 2.34
}
```

#### `GET /api/v1/risk/priority-zones`

Obtenir les zones prioritaires.

#### `GET /api/v1/risk/statistics`

Statistiques globales.

---

### ğŸ–¼ï¸ Classification

#### `POST /api/v1/classification/classify`

Classifier une image de dÃ©chet.

**Body (multipart/form-data):**
- `image`: Fichier image (JPEG/PNG)
- `report_id` (optionnel): ID du report
- `save_result` (optionnel): Sauvegarder en BD

**RÃ©ponse:**
```json
{
  "waste_type": "plastique",
  "confidence": 89.5,
  "probabilities": {
    "plastique": 0.895,
    "papier": 0.045,
    "aluminium": 0.035
  },
  "is_valid": true,
  "processing_time": 0.45
}
```

#### `GET /api/v1/classification/classes`

Liste des classes supportÃ©es.

#### `POST /api/v1/classification/batch-classify`

Classification en batch.

---

### ğŸ“ Estimation de Taille

#### `POST /api/v1/size/estimate`

Estimer la taille d'un tas de dÃ©chets.

**Body (multipart/form-data):**
- `image`: Fichier image
- `report_id` (optionnel)
- `reference_height` (optionnel): Hauteur de rÃ©fÃ©rence (m)

**RÃ©ponse:**
```json
{
  "volume": 2.5,
  "area": 5.0,
  "height": 0.5,
  "confidence": 75.0,
  "unit": "metric",
  "methodology": "depth_estimation",
  "processing_time": 0.67
}
```

---

## ğŸ¤– ModÃ¨les IA

### 1. Classificateur de DÃ©chets

- **Architecture**: MobileNetV2 + Transfer Learning
- **Classes**: 9 types de dÃ©chets
- **Input**: Images 224x224 RGB
- **Accuracy**: ~85% (validation)
- **Fichier**: `waste_classifier_v1.h5`

**EntraÃ®nement:**
```bash
python scripts/train_classifier.py
```

### 2. PrÃ©dicteur de Risque

- **Algorithme**: Gradient Boosting Classifier
- **Features**: 7 features spatiotemporelles
- **Classes**: 4 niveaux de risque
- **Accuracy**: ~78%
- **Fichier**: `risk_predictor.pkl`

**EntraÃ®nement:**
```bash
python scripts/train_risk_model.py
```

### 3. Estimateur de Taille

- **MÃ©thode**: Computer Vision heuristique
- **Mode**: MOCK (proof of concept)
- **AmÃ©lioration**: Depth estimation avec CNN

---

## âœ… Tests

### Lancer tous les tests
```bash
pytest tests/ -v
```

### Tests spÃ©cifiques
```bash
# Tests API
pytest tests/test_api.py -v

# Tests modÃ¨les
pytest tests/test_models.py -v

# Tests services
pytest tests/test_services.py -v
```

### Coverage
```bash
pytest --cov=app tests/
```

---

## ğŸ³ DÃ©ploiement Docker

### Build & Run
```bash
# Build
docker-compose -f docker/docker-compose.yml build

# Start
docker-compose -f docker/docker-compose.yml up -d

# Logs
docker-compose -f docker/docker-compose.yml logs -f

# Stop
docker-compose -f docker/docker-compose.yml down
```

### Services

- **Backend API**: http://localhost:8000
- **PostgreSQL**: localhost:5432
- **pgAdmin**: http://localhost:5050

---

## ğŸ‘¥ Contribution

### Workflow

1. Fork le projet
2. CrÃ©er une branche (`git checkout -b feature/AmazingFeature`)
3. Commit (`git commit -m 'Add AmazingFeature'`)
4. Push (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

### Standards

- Code style: **Black**
- Docstrings: **Google Style**
- Tests: **pytest**
- Type hints: **mypy**

---

## ğŸ“„ Licence

Ce projet est sous licence **MIT**. Voir [LICENSE](LICENSE) pour plus de dÃ©tails.

---

## ğŸ‘¨â€ğŸ’» Auteurs

- **Waste Management AI Team**
- Contact: [email@example.com](mailto:email@example.com)

---

## ğŸ™ Remerciements

- Laravel Backend Team
- Anthropic (Claude)
- HuggingFace
- TensorFlow Community

---

## ğŸ“š Documentation Additionnelle

- [Guide d'EntraÃ®nement](docs/TRAINING.md)
- [Guide API](docs/API.md)
- [Architecture DÃ©taillÃ©e](docs/ARCHITECTURE.md)
- [FAQ](docs/FAQ.md)

---

**â­ N'oubliez pas de mettre une Ã©toile si ce projet vous aide !**